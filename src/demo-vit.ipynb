{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05a1dff5c094186abc243799b698f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)rocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d05d2436f38d47318335a3fbbbd81ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/69.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5fd665a66fe47fb99c2f92eebebdc93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Egyptian cat\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ViT(Image Classification): t\n",
    "\"\"\"\n",
    "\n",
    "from transformers import ViTImageProcessor, ViTForImageClassification\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
    "\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits\n",
    "# model predicts one of the 1000 ImageNet classes\n",
    "predicted_class_idx = logits.argmax(-1).item()\n",
    "print(\"Predicted class:\", model.config.id2label[predicted_class_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "871a638eb28f40baaf78b066051601c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)rocessor_config.json:   0%|          | 0.00/274 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd1615177354b54946d08a9fd4565de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/4.59k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af12b69514c542779973cbe524d5154b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/167M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rsb-weights/resnet50_a1_0-14fe96d1.pth\" to /home/jovyan/.cache/torch/hub/checkpoints/resnet50_a1_0-14fe96d1.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected remote with confidence 0.998 at location [40.16, 70.81, 175.55, 117.98]\n",
      "Detected remote with confidence 0.996 at location [333.24, 72.55, 368.33, 187.66]\n",
      "Detected couch with confidence 0.995 at location [-0.02, 1.15, 639.73, 473.76]\n",
      "Detected cat with confidence 0.999 at location [13.24, 52.05, 314.02, 470.93]\n",
      "Detected cat with confidence 0.999 at location [345.4, 23.85, 640.37, 368.72]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DETR(Object Detection): https://huggingface.co/facebook/detr-resnet-50\n",
    "\"\"\"\n",
    "\n",
    "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "#矩形を描画した画像の保存のためのコードを追記\n",
    "from PIL import ImageDraw\n",
    "# 矩形の描画の準備\n",
    "draw = ImageDraw.Draw(image)\n",
    "# 線の太さ\n",
    "linewidth = 4\n",
    "\n",
    "processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n",
    "model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\")\n",
    "\n",
    "# 矩形の線の色\n",
    "import numpy as np\n",
    "np.random.seed(seed=45)\n",
    "colorset = np.random.randint(0, 256, (len(model.config.id2label), 3))\n",
    "\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# convert outputs (bounding boxes and class logits) to COCO API\n",
    "# let's only keep detections with score > 0.9\n",
    "target_sizes = torch.tensor([image.size[::-1]])\n",
    "results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.9)[0]\n",
    "\n",
    "for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "    box = [round(i, 2) for i in box.tolist()]\n",
    "    print(\n",
    "            f\"Detected {model.config.id2label[label.item()]} with confidence \"\n",
    "            f\"{round(score.item(), 3)} at location {box}\"\n",
    "    )\n",
    "    \n",
    "    # 矩形の描画\n",
    "    rectcolor = tuple(colorset[label])\n",
    "    draw.rectangle([tuple(map(int,box[0:2])), tuple(map(int,box[2:])) ], \\\n",
    "               outline=tuple(rectcolor), width=linewidth) \n",
    "# ファイルの保存\n",
    "image.save(\"img_file_detr_out.png\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "OWL-ViT: https://huggingface.co/google/owlvit-large-patch14\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "from transformers import OwlViTProcessor, OwlViTForObjectDetection\n",
    "\n",
    "#矩形を描画した画像の保存のためのコードを追記\n",
    "from PIL import ImageDraw\n",
    "# 矩形の描画の準備\n",
    "draw = ImageDraw.Draw(image)\n",
    "# 線の太さ\n",
    "linewidth = 4\n",
    "# 矩形の描画\n",
    "rectcolor = (255,0,0)\n",
    "\n",
    "processor = OwlViTProcessor.from_pretrained(\"google/owlvit-large-patch14\")\n",
    "model = OwlViTForObjectDetection.from_pretrained(\"google/owlvit-large-patch14\")\n",
    "\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "texts = [[\"a photo of a cat\", \"a photo of a dog\"]]\n",
    "inputs = processor(text=texts, images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# Target image sizes (height, width) to rescale box predictions [batch_size, 2]\n",
    "target_sizes = torch.Tensor([image.size[::-1]])\n",
    "# Convert outputs (bounding boxes and class logits) to COCO API\n",
    "results = processor.post_process(outputs=outputs, target_sizes=target_sizes)\n",
    "\n",
    "i = 0  # Retrieve predictions for the first image for the corresponding text queries\n",
    "text = texts[i]\n",
    "boxes, scores, labels = results[i][\"boxes\"], results[i][\"scores\"], results[i][\"labels\"]\n",
    "\n",
    "# Print detected objects and rescaled box coordinates\n",
    "score_threshold = 0.1\n",
    "for box, score, label in zip(boxes, scores, labels):\n",
    "    box = [round(i, 2) for i in box.tolist()]\n",
    "    if score >= score_threshold:\n",
    "        print(f\"Detected {text[label]} with confidence {round(score.item(), 3)} at location {box}\")\n",
    "        # 矩形の描画\n",
    "        draw.rectangle([tuple(map(int,box[0:2])), tuple(map(int,box[2:])) ], \\\n",
    "                   outline=rectcolor, width=linewidth) \n",
    "# ファイルの保存\n",
    "image.save(\"img_file_owlvit_out.png\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
